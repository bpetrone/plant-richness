---
title: "Figure 2e, S8"
output:
  html_document:
    df_print: paged
    fig_width: 8
    fig_height: 3.5
---

# Setup

```{r libraries, include=FALSE, echo=FALSE}
library(phyloseq)
library(tidyverse)
```

```{r include=FALSE, echo=FALSE}
# Plotting themes
theme_set(theme_bw() +
               theme(
                    axis.text = element_text(size = 12),
                    axis.title = element_text(size = 14,
                                              face = 'bold'),
                    strip.text = element_text(size = 14,
                                              face = 'bold')
                     )
)
```

# Read in data

```{r}
# trnL phyloseq object
ps <- readRDS('data/phyloseq_trnL.rds')

# alpha diversity
alpha <- readRDS('data/alpha.rds')

# dietary indices from DHQ3 FFQ
ffq <- read_csv('data/Adult-1 and Adult-2 dietary indices.csv')
```

# Pre-process

```{r}
# Filter trnL data to successfully sequenced Adult-1 and -2 samples
ps <- subset_samples(ps, study %in% c('Adult-1', 'Adult-2')) 
ps <- prune_samples(sample_sums(ps) > 0, ps)

# Move forward with pMR only
alpha <- 
     alpha |> 
     filter(grepl(name, pattern = 'CHOMP|ONR')) |> 
     filter(measure == 'Richness' & rarefied == 'Raw') |> 
     select(-rarefied)
```

```{r}
# Add in relevant sample metadata
samdf <- 
     ps@sam_data |>
     data.frame() |> 
     rownames_to_column(var = 'row') |> 
     select(row, 
            study, 
            subj, 
            starts_with('CH_'), 
            starts_with('ONR_')) 

alpha <-
    left_join(samdf,
              alpha,
              by = c('row' = 'name'),
              multiple = 'all')
```

```{r}
# Filter to dietary indices that will be tested below
ffq <- 
     ffq |> 
     filter(pass_qc) |> 
     select(study, 
            subj,
            hei_plant_all,
            hPDI,
            fvs_plant_residual)
```

# Subsampling

First, want to enumerate sampling schemes.
- 1: One sample, anytime
- 2: Two consecutive samples (adjacent days)-- ADULT-1 ONLY
- 3: NHANES spacing: two samples spaced between 3-10 days apart
- 4: 3 weeks of weekly samples
- 5: 4 " " " "-- ADULT-1 ONLY
- 6: 5 " " " "-- ADULT-1 ONLY
- 7: 6 " " " " -- ADULT-1 ONLY

```{r}
alpha.1 <- filter(alpha, study == 'Adult-1')
alpha.2 <- filter(alpha, study == 'Adult-2')

samdf.1 <- filter(samdf, study == 'Adult-1')
samdf.2 <- filter(samdf, study == 'Adult-2')
```

## Adult-1 

```{r}
# Make dataframe for storing results
results.df.1 <- data.frame(
     scheme = NULL, 
     study = NULL,
     index = NULL,
     rho = NULL,
     p = NULL)
```

#### Scheme 1

Note that this will cover duplicated sample sets as i gets closer to 18, but can detect and remove them downstream.
```{r}
# Do scheme 1 first: 1 sample from each participant
set.seed(1222022)

for (iter in (1:100)){
     # Make subsampled, merged phyloseq
     samples <- 
          alpha.1 |> 
          group_by(subj) |> 
          slice_sample(n = 1) |> 
          pull(row)
     
     # Join to FVS
     alpha.temp <- 
          alpha.1 |> 
          filter(row %in% samples) |> 
          left_join(ffq, by = c('study', 'subj'))
     
     # Calculate correlation:
     # For HEI plant:
     spearman <- cor.test(alpha.temp$value, 
                                           alpha.temp$hei_plant_all,
                                           method = 'spearman', exact = FALSE)
     # Update results dataframe
     row <- c(1, 
              'Adult-1', 
              'HEI plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
     
     # For pDI: 
     spearman <- cor.test(alpha.temp$value, 
                                           alpha.temp$hPDI,
                                           method = 'spearman', exact = FALSE)
     
     # Update results dataframe
     row <- c(1, 
              'Adult-1', 
              'hPDI',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
     
     # For FVS plant:
     spearman <- cor.test(alpha.temp$value, 
                                           alpha.temp$fvs_plant_residual,
                                           method = 'spearman', exact = FALSE)
     
     # Update results dataframe
     row <- c(1, 
              'Adult-1', 
              'FVS plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
}
```

#### 2

Scheme 2: Two consecutive daily samples
First to subset to only the samples that we know have one adjacent to them.  Then, at each iteration, could randomly pick one sample per participant, and then randomly pick one of its adjoining samples.

```{r}
# Make a sample "distance matrix"
d <- 
     dist(samdf.1$CH_day) |> 
     as.matrix() 

colnames(d) <- rownames(d) <- samdf.1$row
```

```{r}
adjacent <- list()
for (s in unique(samdf.1$subj)){
     # For each subject, make a list of samples that are adjacent to at least 
     # one other sample
     
     # Get all the samples for that subject
     samples <- 
          filter(samdf.1,
                 subj == s) |> 
          pull(row)
     
     # Subset the distance matrix
     d.temp <- d[samples, samples]
     
     # Pull any column that has a 1 (indicating a consecutive day from at least
     # one other subject)
     adjacent[[s]] <- 
          apply(d.temp, 2, function(x){any(x == 1)}) |> 
          which() |> 
          names()
}
```

```{r}
# How many subjects have at least one consecutive sample?
lapply(adjacent, length) |> 
     unlist()
```

```{r}
# Drop those without (this naturally removes Adult-2 subjects)
adjacent <- 
     adjacent[lapply(adjacent, 
                     function(x){length(x) > 0}) |> 
                   unlist()]

length(adjacent)
```

Okay, so now want to calculate correlation from here. 
```{r}
set.seed(1232022)

for (iter in (1:100)){
     adjacent.df <- data.frame()
     for (s in names(adjacent)){
          # Randomly sample one of that subject's samples
          s1 <- sample(adjacent[[s]],
                       size = 1)
          
          # Subset the distance matrix to only that subject's samples
          d.temp <- d[s1, adjacent[[s]]]
          s2s <- 
               which(d.temp == 1) |> 
               names()
               
          # Find another sample that's 1 day away in distance
          s2 <- sample(s2s, size = 1)
          
          # Pull observed values, calculate mean, join to FFQ
          alpha.temp <- 
               alpha.1 |> 
               filter(row %in% c(s1, s2)) |> 
               group_by(subj) |> 
               summarize(value = mean(value)) |> 
               left_join(ffq, by = c('subj'))
          
          # Add to the running list of values for this iteration
          adjacent.df <- bind_rows(adjacent.df,
                                   alpha.temp)
     }
          
     # Calculate correlation
     # For HEI plant:
     spearman <- cor.test(adjacent.df$value, 
                                           adjacent.df$hei_plant_all,
                                           method = 'spearman', exact = FALSE)
     # Update results dataframe
     row <- c(2, 
              'Adult-1', 
              'HEI plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
     
     # For pDI: 
     spearman <- cor.test(adjacent.df$value, 
                                           adjacent.df$hPDI,
                                           method = 'spearman', exact = FALSE)
     
     # Update results dataframe
     row <- c(2, 
              'Adult-1', 
              'hPDI',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
     
     # For FVS plant:
     spearman <- cor.test(adjacent.df$value, 
                                           adjacent.df$fvs_plant_residual,
                                           method = 'spearman', exact = FALSE)
     
     # Update results dataframe
     row <- c(2, 
              'Adult-1', 
              'FVS plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
}
```

#### 3

```{r}
nhanes <- list()
for (s in unique(samdf.1$subj)){
     # For each subject, make a list of samples that are 3-10 days from least 
     # one other sample
     
     # Get all the samples for that subject
     samples <- 
          filter(samdf.1,
                 subj == s) |> 
          pull(row)
     
     # Subset the distance matrix
     d.temp <- d[samples, samples]
     
     # Pull any column that has a 1 (indicating a consecutive day from at least
     # one other subject)
     nhanes[[s]] <- 
          apply(d.temp, 2, function(x){any(x %in% 3:10)}) |> 
          which() |> 
          names()
}
```

```{r}
# Unlike adjacent sampling, this includes all subjects
length(nhanes)
```

Okay, so now want to calculate correlation from here. 
```{r}
set.seed(1232022)

for (iter in (1:100)){
     nhanes.df <- data.frame()
     for (s in names(nhanes)){
          # Randomly sample one of that subject's samples
          s1 <- sample(nhanes[[s]],
                       size = 1)
          
          # Subset the distance matrix to only that subject's samples
          d.temp <- d[s1, nhanes[[s]]]
          s2s <- names(d.temp)[d.temp %in% 3:10]
               
          # Find another sample that's 1 day away in distance
          s2 <- sample(s2s, size = 1)
          
          # Pull observed values, calculate mean, join to FVS
          alpha.temp <- 
               alpha.1 |> 
               filter(row %in% c(s1, s2)) |> 
               group_by(subj) |> 
               summarize(value = mean(value)) |> 
               left_join(ffq, by = c('subj'))
          
          # Add to the running list of values for this iteration
          nhanes.df <- bind_rows(nhanes.df,
                                 alpha.temp)
     }
          
     # Calculate correlation
     # HEI plant
     spearman <- cor.test(nhanes.df$value, 
                                           nhanes.df$hei_plant_all,
                                           method = 'spearman', exact = FALSE)
     
     # Update results dataframe
     row <- c(3, 
              'Adult-1', 
              'HEI plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
     
     # hPDI
     spearman <- cor.test(nhanes.df$value, 
                                           nhanes.df$hPDI,
                                           method = 'spearman', exact = FALSE)
     
     # Update results dataframe
     row <- c(3, 
              'Adult-1', 
              'hPDI',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
     
     # FVS plant
     spearman <- cor.test(nhanes.df$value, 
                                           nhanes.df$fvs_plant_residual,
                                           method = 'spearman', exact = FALSE)
     
     # Update results dataframe
     row <- c(3, 
              'Adult-1', 
              'FVS plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.1 <- bind_rows(results.df.1, row)
}
```

#### 4 through 7 (weekly)

```{r}
# Schemes 4-7 (3 to 6 weeks of weekly sampling)
set.seed(1232021)

for (i in 3:6){ # Number of samples (only from separate weeks)
     for (iter in (1:100)){
          # Subsample
          samples <- 
               alpha.1 |> 
               group_by(subj, CH_week) |> 
               slice_sample(n = 1) |> # Pick one sample from each week at random
               ungroup() # 6 random weekly samples

          # Now, based on # samples needed, randomly sample a starting week
          # that will provide the right number of consecutive samples
          # 3: start_week from 1 to 4
          # 4: start_week from 1 to 3
          # 5: start_week from 1 to 2
          # 6: start_week is 1
          
          start_week_max <- 6 - i + 1
          samples_start <- 
               samples |> 
               filter(CH_week <= start_week_max) |> 
               group_by(subj) |> 
               arrange(subj, CH_week) |> 
               slice_sample(n = 1) |> 
               select(subj, 
                      CH_week_start = CH_week)
          
          # Now join back to randomly selected samples
          samples <- 
               samples |> 
               left_join(samples_start, by = 'subj') |> 
               # Choose the right number of weeks
               filter(CH_week >= CH_week_start & 
                           CH_week < CH_week_start + i) |> 
               # Pull sample names
               pull(row)
          
          # Pull observed values, calculate mean, join to FVS
          alpha.temp <- 
               alpha.1 |> 
               filter(row %in% samples) |> 
               group_by(subj) |> 
               summarize(value = mean(value)) |> 
               left_join(ffq, by = c('subj'))
          
          # Calculate correlation
          # HEI plant
          spearman <- cor.test(alpha.temp$value, 
                               alpha.temp$hei_plant_all,
                               method = 'spearman',
                               exact = FALSE)
          
          # Update results dataframe
          row <- c(i + 1, 
                   'Adult-1', 
                   'HEI plant',
                   spearman$estimate, 
                   spearman$p.value)
          names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
          results.df.1 <- bind_rows(results.df.1, row)
          
          # hPDI
          spearman <- cor.test(alpha.temp$value, 
                                alpha.temp$hPDI,
                                method = 'spearman', 
                                exact = FALSE)
          
          # Update results dataframe
          row <- c(i + 1, 
                   'Adult-1', 
                   'hPDI',
                   spearman$estimate, 
                   spearman$p.value)
          names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
          results.df.1 <- bind_rows(results.df.1, row)
          
          # FVS plant
          spearman <- cor.test(alpha.temp$value, 
                               alpha.temp$fvs_plant_residual,
                               method = 'spearman', 
                               exact = FALSE)
          
          # Update results dataframe
          row <- c(i + 1, 
                   'Adult-1', 
                   'FVS plant',
                   spearman$estimate, 
                   spearman$p.value)
          names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
          results.df.1 <- bind_rows(results.df.1, row)
     }
}
```

## Adult 2

Same as above, except can only do schemes:
- 1: One sample, anytime
- 3: NHANES spacing: two samples spaced between 3-10 days apart
- 4: 3 weeks of weekly samples

```{r}
# For storing results
results.df.2 <- data.frame(
     scheme = NULL, 
     study = NULL,
     index = NULL,
     rho = NULL,
     p = NULL)
```

####  1

```{r}
# Do scheme 1 first: 1 sample from each participant
set.seed(1222022)

for (iter in (1:100)){
     # Make subsampled, merged phyloseq
     samples <- 
          alpha.2 |> 
          group_by(subj) |> 
          slice_sample(n = 1) |> 
          pull(row)
     
     # Join to FVS
     alpha.temp <- 
          alpha.2 |> 
          filter(row %in% samples) |> 
          left_join(ffq, by = 'subj')
     
     # Calculate correlation:
     # For HEI plant:
     spearman <- cor.test(alpha.temp$value, 
                          alpha.temp$hei_plant_all,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(1, 
              'Adult-2', 
              'HEI plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
     
     # For pDI: 
     spearman <- cor.test(alpha.temp$value, 
                          alpha.temp$hPDI,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(1, 
              'Adult-2', 
              'hPDI',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
     
     # For FVS plant:
     spearman <- cor.test(alpha.temp$value, 
                          alpha.temp$fvs_plant_residual,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(1, 
              'Adult-2', 
              'FVS plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
}
```

### 3

```{r}
# Make a sample "distance matrix"
d <- 
     dist(samdf.2$ONR_day) |> 
     as.matrix() 

colnames(d) <- rownames(d) <- samdf.2$row
```

```{r}
nhanes <- list()
for (s in unique(samdf.2$subj)){
     # For each subject, make a list of samples that are 3-10 days from least 
     # one other sample
     
     # Get all the samples for that subject
     samples <- 
          filter(samdf.2,
                 subj == s) |> 
          pull(row)
     
     # Subset the distance matrix
     d.temp <- d[samples, samples]
     
     # Pull any column that has a 1 (indicating a consecutive day from at least
     # one other subject)
     nhanes[[s]] <- 
          apply(d.temp, 2, function(x){any(x %in% 3:10)}) |> 
          which() |> 
          names()
}
```

```{r}
# Unlike adjacent sampling, this includes all subjects
length(nhanes)
```

Okay, so now want to calculate correlation from here. 
```{r}
set.seed(1232022)

for (iter in (1:100)){
     nhanes.df <- data.frame()
     for (s in names(nhanes)){
          # Randomly sample one of that subject's samples
          s1 <- sample(nhanes[[s]],
                       size = 1)
          
          # Subset the distance matrix to only that subject's samples
          d.temp <- d[s1, nhanes[[s]]]
          s2s <- names(d.temp)[d.temp %in% 3:10]
               
          # Find another sample that's 1 day away in distance
          s2 <- sample(s2s, size = 1)
          
          # Pull observed values, calculate mean, join to FVS
          alpha.temp <- 
               alpha.2 |> 
               filter(row %in% c(s1, s2)) |> 
               group_by(subj) |> 
               summarize(value = mean(value)) |> 
               left_join(ffq, by = c('subj'))
          
          # Add to the running list of values for this iteration
          nhanes.df <- bind_rows(nhanes.df,
                                 alpha.temp)
     }
          
     # Calculate correlation
     # HEI plant
     # Common warning: cannot compute exact p-value with ties
     spearman <- cor.test(nhanes.df$value, 
                          nhanes.df$hei_plant_all,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(3, 
              'Adult-2', 
              'HEI plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
     
     # hPDI
     spearman <- cor.test(nhanes.df$value, 
                          nhanes.df$hPDI,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(3, 
              'Adult-2', 
              'hPDI',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
     
     # FVS plant
     spearman <- cor.test(nhanes.df$value, 
                          nhanes.df$fvs_plant_residual,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(3, 
              'Adult-2', 
              'FVS plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
}
```

#### 4 

```{r}
# Scheme 4 (3 weeks of weekly sampling)
# Can hard code values here, because for ONR it amounts to one per week
set.seed(1232021)

for (iter in (1:100)){
     # Subsample
     samples <- 
          samdf |> 
          group_by(subj, ONR_week) |> 
          slice_sample(n = 1) |> # Pick one sample from each week at random
          ungroup() |>  # 3 random weekly samples
          pull(row)
     
     # Here, this is all we need: 3 consecutive weeks
     # Pull observed values, calculate mean, join to FVS
     alpha.temp <- 
          alpha.2 |> 
          filter(row %in% samples) |> 
          group_by(subj) |> 
          summarize(value = mean(value)) |> 
          left_join(ffq, by = c('subj'))
     
     # Calculate correlation
     # HEI plant
     spearman <- cor.test(alpha.temp$value, 
                          alpha.temp$hei_plant_all,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(4, 
              'Adult-2', 
              'HEI plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
     
     # hPDI
     spearman <- cor.test(alpha.temp$value, 
                          alpha.temp$hPDI,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(4, 
              'Adult-2', 
              'hPDI',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
     
     # FVS plant
     spearman <- cor.test(alpha.temp$value, 
                          alpha.temp$fvs_plant_residual,
                          method = 'spearman', 
                          exact = FALSE)
     
     # Update results dataframe
     row <- c(4, 
              'Adult-2', 
              'FVS plant',
              spearman$estimate, 
              spearman$p.value)
     names(row) <- c('scheme', 'study', 'index', 'rho', 'p')
     results.df.2 <- bind_rows(results.df.2, row)
}
```

## Summarize and plot

```{r}
# Join
results.df <- 
     bind_rows(results.df.1,
               results.df.2)

rm(results.df.1,
   results.df.2)
```

```{r}
# Summarize duplicates 
results.df |> 
     group_by(scheme, study, index) |> 
     distinct() |> 
     count() |> 
     filter(n < 100)
```

```{r}
# Remove duplicates
dim(results.df)
results.df <- distinct(results.df)
dim(results.df) 
```

```{r}
cols = c('scheme', 'rho', 'p')
results.df <- 
     mutate(results.df,
            across(one_of(cols),
            ~ as.numeric(.x)))
```

### 80% or more

What fraction of random shuffles were p<0.05?

```{r}
signif <- 
     results.df |> 
     group_by(study, index, scheme) |> 
     summarize(significant = sum(p <= 0.05),
               total = length(p)) |> 
     mutate(percentage = significant/total) |> 
     # Recode percentage as 50-80%, or >80%
     mutate(percentage_cat = 
                 cut(percentage,
                     breaks = c(0, .5, .8, 1.1),
                     right = FALSE))

signif
```

```{r}
# Recode categorical percentages
signif <- 
     signif |> 
     select(study, index, scheme, percentage = percentage_cat) |> 
     ungroup() |> 
     mutate(percentage = factor(percentage,
                                labels = 
                                     c('<50%',
                                       '50-80%',
                                       '>=80%')))
```

### Set intercept

```{r}
# Intercept: get from full dataset
alpha <- 
     alpha |> 
     group_by(study, subj) |> 
     summarize(value = mean(value)) |> 
     full_join(ffq)

alpha
```
```{r}
# Differences from reported due to filtering
alpha |> 
     group_by(study) |> 
     summarize(rho = cor.test(~ value + hei_plant_all,
                              method = 'spearman',
                              exact = FALSE)$estimate,
               p = cor.test(~ value + hei_plant_all,
                            method = 'spearman',
                            exact = FALSE)$p.value)
```

```{r}
alpha |> 
     group_by(study) |> 
     summarize(rho = cor.test(~ value + hPDI,
                              method = 'spearman',
                              exact = FALSE)$estimate,
               p = cor.test(~ value + hPDI,
                            method = 'spearman',
                            exact = FALSE)$p.value)
```

```{r}
alpha |> 
     group_by(study) |> 
     summarize(rho = cor.test(~ value + fvs_plant_residual,
                              method = 'spearman',
                              exact = FALSE)$estimate,
               p = cor.test(~ value + fvs_plant_residual,
                            method = 'spearman',
                            exact = FALSE)$p.value)
```

```{r}
rho.df <- 
     data.frame(
          study = rep(c('Adult-1', 'Adult-2'), 3),
          index = c(rep('HEI plant', 2),
                    rep('hPDI', 2),
                    rep('FVS plant', 2)),
          rho_full = c(0.4173962, # Adult-1 HEI plant
                       0.3992474, # Adult-2 HEI plant
                       0.5232039, # Adult-1 hPDI
                       0.6336815, # Adult-2 hPDI
                       0.6156453, # Adult-1 FVS
                       0.5022239) # Adult-2 FVS
     )
rho.df
```
```{r}
# Join to results
results.df <- 
     results.df |> 
     left_join(rho.df) |> 
     left_join(signif)
```

```{r}
# Add empty values for Adult-2 for better plotting
empty <- 
     data.frame(scheme = c(2,5:7),
                study = 'Adult-2',
                rho = NA,
                p = NA,
                percentage = NA) |> 
     left_join(rho.df,
               multiple = 'all')

results.df <- bind_rows(results.df, empty)
rm(empty, rho.df)
```

```{r}
# Sampling scheme labels:
results.df$scheme <- 
     factor(results.df$scheme,
            levels = 1:7,
            labels = c('Single sample',
                       'Two samples (1d apart)', 
                       'Two samples (3-10d apart)',
                       'Three samples (1/wk)',
                       'Four samples (1/wk)',
                       'Five samples (1/wk)',
                       'Six samples (1/wk)')
     )
```

```{r}
# Refactor for plotting
results.df$index <- 
     factor(results.df$index,
            levels = c('FVS plant',
                       'hPDI',
                       'HEI plant'),
            labels = c('FVS score residuals\n(plant items)',
                       'hPDI',
                       'HEI-2015\n(plant component)'))
```

```{r}
# Plot
results.df |> 
     filter(study == 'Adult-1') |> 
     ggplot(aes(x = scheme, y = rho, group = scheme)) +
     geom_hline(aes(yintercept = rho_full),
                linetype = 'dotted',
                color = 'gray',
                size = 1) +
     geom_boxplot(aes(fill = percentage)) +
     scale_fill_manual(values = c('#ff684c',
                                  '#ffda66',
                                  '#8ace7e')) +
     facet_grid(cols = vars(index),
                rows = vars(study)) +
     labs(y = 'Spearman *rho*', 
          x = 'Sampling scheme',
          fill = '*p* values\n<0.05') +
     theme(axis.title.y = ggtext::element_markdown(),
           legend.title = ggtext::element_markdown(),
           strip.text = element_text(size = 12, face = 'bold'), 
           axis.text.x = element_text(angle = 40, 
                                      hjust = 1,
                                      size = 9),
           panel.grid.minor.x = element_blank())
```
```{r}
# ggsave('Fig 2e.pdf', height = 3.5, width = 8)
```

```{r}
# Plot
results.df |> 
     filter(study == 'Adult-2') |> 
     ggplot(aes(x = scheme, y = rho, group = scheme)) +
     geom_hline(aes(yintercept = rho_full),
                linetype = 'dotted',
                color = 'gray',
                size = 1) +
     geom_boxplot(aes(fill = percentage)) +
     scale_fill_manual(values = c('#ff684c',
                                  '#ffda66',
                                  '#8ace7e')) +
     facet_grid(cols = vars(index),
                rows = vars(study)) +
     labs(y = 'Spearman *rho*', 
          x = 'Sampling scheme',
          fill = '*p* values\n<0.05') +
     theme(axis.title.y = ggtext::element_markdown(),
           legend.title = ggtext::element_markdown(),
           strip.text = element_text(size = 12, face = 'bold'), 
           axis.text.x = element_text(angle = 40, 
                                      hjust = 1,
                                      size = 9),
           panel.grid.minor.x = element_blank())
```

```{r}
# ggsave('Fig S8.pdf', height = 3.5, width = 8)
```

